\@doanenote {1}
macro:->\doublespacing
An
incomplete
list
of
recent
work
would
include
\citet
{Krause:1997},
\citet
{Davies:Gurr:1998},
\citet
{Pevehouse:Goldstein:1999},
\citet
{Schrodt:Gerner:2000},
\citet
{King:Zeng:2001},
\citet
{OBrien:2002},
\citet
{BDM:2002},
\citet
{Fearon:Laitin:2003},
\citet
{Demarchi:etal:2004},
\citet
{Enders:Sandler:2005},
\citet
{Leblang:Satyanath:2006},
\ifthenelse
{\boolean
{blind}}{\citet
{Author:2020b}}{\citet
{Ward:etal:2007}},
\citet
{Brandt:etal:2008},
\citet
{Bennett:Stam:2009},
and
\ifthenelse
{\boolean
{blind}}{\citet
{Author:2020}}{\citet
{Gleditsch:Ward:2010}}.
A
summary
of
classified
efforts
is
reported
in
\citet
{Feder:2002}.
An
overview
of
some
of
the
historical
efforts
along
with
a
description
of
current
thinking
about
forecasting
and
decision-support
is
given
by
\citet
{OBrien:2010}.
\vspace
{4
mm}
\@endanenote 
\@doanenote {2}
macro:->\doublespacing
\citet
{Lewis-Beck:2005}
provides
a
more
in-depth
discussion
of
election
forecasting
in
a
comparative
context.
\vspace
{4
mm}
\@endanenote 
\@doanenote {3}
macro:->\doublespacing
The
case
for
using
predictions
heuristically
can
also
be
found
in
early
work
by
\citet
{Dawid:1982,
Dawid:1984}.
\vspace
{4
mm}
\@endanenote 
\@doanenote {4}
macro:->\doublespacing
To
fully
capture
the
ability
of
EBMA
to
reduce
over-fitting
when
using
statistical
models
it
is
necessary
to
divide
the
data
into
three
periods
\citep
{Hastie:2009}.
The
first
period,
the
training
period,
is
used
to
fit
the
parameters
for
each
component
model.
The
second
period,
the
validation
period,
is
used
to
calculate
model
weights
and
other
parameters
for
the
EBMA
model
using
out-of-sample
predictions
generated
from
the
component
models.
We
then
generate
ensemble
predictions
for
the
third
period,
the
test
period,
using
the
EBMA
model
parameters
calculated
in
period
two.
This
approach
is
explicit
in
the
insurgency
forecasting
example
below
and
implicit
in
the
Supreme
Court
example
below
since
the
subject-experts
and
classification
algorithm
were
``trained''
on
data
not
included
in
the
study.
This
three-stage
method
is
adjusted
in
the
election
forecasting
example
as
the
component
models
are
already
sparse
(somewhat
ameliorating
concerns
about
over-fitting)
and
there
are
a
much
smaller
number
of
observations.
In
this
example,
component
models
are
trained
over
the
period
beginning
in
1916
and
the
EBMA
parameters
are
calculated
only
for
the
period
beginning
in
1952.
However,
there
is
significant
overlap
in
the
training
and
validation
samples.
\label
{samples}
\vspace
{4
mm}
\@endanenote 
\@doanenote {5}
macro:->\doublespacing
In
the
case
of
subject-experts,
the
training
period
is
implicitly
the
period
over
which
experts
have
gained
their
experience.
Forecasts
will
only
be
necessary
for
the
validation
period.
\vspace
{4
mm}
\@endanenote 
\@doanenote {6}
macro:->\doublespacing
\citet
{Sloughter:2007}
make
predictions
for
only
one
future
time
period,
and
use
only
a
subset
of
past
time-periods
(they
recommend
30)
in
their
validation
period.
Thus,
predictions
are
made
sequentially
with
the
entire
EBMA
procedure
being
re-calculated
for
each
future
event
as
observations
are
moved
from
the
test
period
$T^\ast
$
into
the
validation
period
$T$.
Another
alternative
is
to
simply
divide
\textit
{all}
the
data
into
discrete
training,
validation
and
test
periods
for
the
entire
procedure.
We
use
both
approaches
in
our
examples
below.
\vspace
{4
mm}
\@endanenote 
\@doanenote {7}
macro:->\doublespacing
Our
adjustments
to
the
basic
EBMA
method
for
application
to
dichotomous
outcomes,
as
well
as
details
of
parameter
estimation,
are
shown
in
Appendix
A.
\vspace
{4
mm}
\@endanenote 
\@doanenote {8}
macro:->\doublespacing
The
twenty-nine
countries
are
Australia,
Bangladesh,
Bhutan,
Cambodia,
China,
Comoros,
Fiji,
India,
Indonesia,
Japan,
Laos,
Madagascar,
Malaysia,
Mauritius,
Mongolia,
Myanmar,
Nepal,
New
Zealand,
North
Korea,
Papua
New
Guinea,
Philippines,
Russia,
Singapore,
Solomon
Islands,
South
Korea,
Sri
Lanka,
Taiwan,
Thailand,
and
Vietnam.
This
set
is
not
a
random
sample,
but
rather
constitutes
the
countries
of
population
greater
than
$500,000$
that
are
in
the
area
of
responsibility
of
the
US
Pacific
Command.
\vspace
{4
mm}
\@endanenote 
\@doanenote {9}
macro:->\doublespacing
Because
some
of
the
models
include
lagged
data,
this
is
the
first
year
for
which
all
of
the
component
models
produce
fitted
values
or
predictions.
\vspace
{4
mm}
\@endanenote 
\@doanenote {10}
macro:->\doublespacing
See
\url
{strategicanalysisenterprises.com}
for
more
details.
All
data
and
models
will
be
included
in
a
replication
dataset
at
the
time
of
publication.
\vspace
{4
mm}
\@endanenote 
\@doanenote {11}
macro:->\doublespacing
It
is
worth
noting
that
the
mixed
effects
model
is
a
kind
of
ensemble
mixture
in
that
in
averages
the
so-called
within
model
with
the
between
model.
\vspace
{4
mm}
\@endanenote 
\@doanenote {12}
macro:->\doublespacing
This
is
calculated
as
the
number
of
days
between
the
middle
of
the
current
month
and
the
last
federal
election
regardless
of
the
legitimacy
of
the
election.
\vspace
{4
mm}
\@endanenote 
\@doanenote {13}
macro:->\doublespacing
Geographical
proximity
is
measured
in
terms
of
the
length
of
the
shared
border
between
the
two
countries.
\vspace
{4
mm}
\@endanenote 
\@doanenote {14}
macro:->\doublespacing
One
alternative
approach
to
generating
ensemble
forecasts
would
be
to
use
the
simple
average
of
each
component
forecast.
However,
this
causes
difficulties
because
the
researcher
must
use
their
own
judgement
to
decide
which
alternative
models
are
sufficiently
accurate
and
diverse
for
inclusion.
EBMA
offers
a
more
statistically
motivated
and
straightforward
method
for
achieving
the
same
end.
In
any
case,
these
simple
averages
do
not
perform
well
against
the
EBMA
forecast.
In
the
current
example,
a
simple
unweighted
average
results
in
$AUC
=
0.885$,
PRE=0.123,
Brier
=
0.052,
and
\%
Correct
=
$92.8$
for
the
test-period.
This
is
not
surprising
given
that
simple
averaging
weights
an
inaccurate
model
the
same
as
an
accurate
one.
EBMA
on
the
other
hand
is
able
to
detect
the
superiority
of
components
and
calibrates
weights
accordingly.
Likewise,
simple
averages
cannot
identify
pairs
or
groups
of
highly
correlated
forecasts
and
will
tend
to
give
these
groupings
too
much
weight.
\vspace
{4
mm}
\@endanenote 
\@doanenote {15}
macro:->\doublespacing
It
is
important
to
note
that
we
attempted
to
replicate
each
of
the
models
for
the
2008
election
as
closely
as
possible
given
the
model
descriptions
in
the
articles
and
the
data
provided
by
the
authors.
We
then
proceeded
to
use
the
same
model
specifications
as
used
in
the
2008
articles
to
forecast
all
elections
previous
to
2008.
Thus,
prior
to
2008
the
individual
model
results
are
not
exact
replications
of
the
author's
given
prediction
for
that
election
year
and
results
may
vary
from
what
was
presented
by
the
authors
as
the
forecast
for
a
given
election.
This
may
be
due
to
changes
in
the
model
specification
over
time
and
data
updates.
Thus,
we
neither
attempted
nor
succeeded
in
replicating
the
exact
forecasts
for
all
election
years
for
all
components.
\vspace
{4
mm}
\@endanenote 
\@doanenote {16}
macro:->\doublespacing
The
model
here
replicates
Equation
1
in
\citet
{Fair:2010}.
\vspace
{4
mm}
\@endanenote 
\@doanenote {17}
macro:->\doublespacing
The
data
to
replicate
the
models
by
\citet
{Abramowitz:2008},
\citet
{Campbell:2008},
\citet
{Erikson:Wlezien:2008},
and
\citet
{Lewis-Beck:Tien:2008}
were
provided
in
personal
correspondence
with
the
respective
authors.
The
remaining
data
were
downloaded
from
the
web
sites
of
Ray
C.
Fair
\nocite
{Fair2011}
(\url
{http://fairmodel.econ.yale.edu/vote2012/tbl1.txt})
and
Douglas
Hibbs
\nocite
{Hibbs2011}
(\url
{http://www.douglas-hibbs.com/}).
\vspace
{4
mm}
\@endanenote 
\@doanenote {18}
macro:->\doublespacing
For
example,
the
Fair
model
uses
data
for
election
results
beginning
in
1916
while
the
Abramowitz
model
begins
with
data
from
the
1952
election.

\vspace
{4
mm}
\@endanenote 
\@doanenote {19}
macro:->\doublespacing
See
footnote
\ref
{samples}
for
additional
discussion
of
the
implications
of
the
overlapping
training
and
validation
samples.
Results
in
this
section
were
computed
using
modifications
of
the
`ensembleBMA'
package
\citep
{Fraley:2010b,
Fraley:Forthcoming}.
Because
of
the
paucity
of
data,
we
did
not
apply
any
bias
correction
to
these
forecasts.
Thus,
the
predictor
and
constant,
denoted
$a_{0k}$
and
$a_{1k}$
above,
are
constrained
to
zero
and
one
respectively.
\vspace
{4
mm}
\@endanenote 
\@doanenote {20}
macro:->\doublespacing
As
we
noted
above,
these
models
are
fit
sequentially,
so
the
validation
periods
change.
For
example,
the
validation
period
for
the
forecast
of
the
2004
election
is
1952-2000.
The
validation-period
RMSE
is
therefore
calculated
for
those
observations.
For
the
2008
election,
the
validation
period
is
1952-2004.\label
{clarity}
\vspace
{4
mm}
\@endanenote 
\@doanenote {21}
macro:->\doublespacing
The
correlation
matrix
between
fitted-values
of
the
model
for
the
1952-2004
period
is:
\\
\par
\begin
{tabular}{l
rrrrrr}
\toprule
&
\textbf
{C}&
\textbf
{A}
&
\textbf
{H}&
\textbf
{F}
&
\textbf
{L}
&
\textbf
{E}
\\
\midrule
\textbf
{C}ampbell&
1.00
&
&
&
&
&
\\
\textbf
{A}bramowitz
&
0.94
&
1.00
&
&
&
&
\\
\textbf
{H}ibbs
&
0.91
&
0.93
&
1.00&
&
&
\\
\textbf
{F}air
&
0.87
&
0.89
&
0.89
&
1.00&
&
\\
\textbf
{L}ewis-Beck/Tien
&
0.93
&
0.96
&
0.91
&
0.88
&
1.00
&
\\
\textbf
{E}WT2C2
&
0.85
&
0.90
&
0.87
&
0.91
&
0.86
&
1.00\\
\bottomrule
\end
{tabular}.
\vspace
{4
mm}
\@endanenote 
\@doanenote {22}
macro:->\doublespacing
\citet
{brandt:freeman:schrodt:2011}
survey
a
variety
of
metrics
in
addition
to
those
we
employ
here.
These
include
measures
of
average
prediction
errors,
measures
using
medians
and
geometric
averages,
measures
that
compare
the
complete
difference
in
probability
distributions,
and
sequential
rank-based
methods.
Although
there
are
many
candidate
metrics,
at
least
for
the
alternative
metrics
we
have
calculated
so
far,
the
substantive
conclusions
we
reach
do
not
change
for
our
examples
and
they
are
not
presented
due
to
space
constraints.
However,
as
suggested
by
a
helpful
reviewer,
we
note
that
there
are
reasons
to
doubt
that
RMSE
or
MAE
will
necessarily
provide
a
ranking
of
component
models
based
on
accuracy.
A
more
complete
approach
evaluating
the
accuracy
of
the
component
models
is
to
examine
the
results
displayed
in
Figure
\ref
{PresPlots2}
below.
\vspace
{4
mm}
\@endanenote 
\@doanenote {23}
macro:->\doublespacing
Additional
details
about
the
project,
replication
files,
as
well
as
a
complete
listing
of
cases
and
expert
forecasts
are
available
at:
\url
{http://wusct.wustl.edu/index.php}.
\vspace
{4
mm}
\@endanenote 
\@doanenote {24}
macro:->\doublespacing
As
noted
above,
these
cases
were
heard
in
the
2002-2003
period.
We
note
that
the
dates
on
the
docket
number
do
not
necessarily
reflect
the
order
in
which
they
were
argued
before
the
court
and
the
order
in
which
cases
were
argued
did
not
correspond
to
when
the
decisions
were
handed
down.
Thus,
there
is
no
obvious
way
to
partition
the
data
into
validation
and
test
periods.
However,
in
general,
the
docket
numbers
roughly
correspond
to
the
age
of
the
case.
Although
partitioning
the
data
in
this
manner
is
slightly
arbitrary,
it
serves
the
limited
purpose
of
demonstrating
the
method.
\vspace
{4
mm}
\@endanenote 
\@doanenote {25}
macro:->\doublespacing
The
baseline
model
here
is
the
prediction
that
all
votes
will
be
to
reverse
the
lower
court.
This
baseline
model
is
correct
for
roughly
70\%
of
the
votes
in
the
test
period.
\vspace
{4
mm}
\@endanenote 
\@doanenote {26}
macro:->\doublespacing
In
addition,
some
scholars
have
advanced
the
argument
that
prediction
is
closely
related
to
the
identification
of
causal
processes
\citep
[e.g.,][]{Spirtes:2000}.
However,
this
is
far
from
a
universally
accepted
position
and
is
not
the
basis
for
our
advocacy
of
increased
forecasting
in
political
science.
\vspace
{4
mm}
\@endanenote 
\@doanenote {27}
macro:->\doublespacing
All
data
used
to
generate
the
results
in
this
article
will
be
made
available
to
the
public
in
the
journal's
dataverse
upon
publication
at
\url
{http://hdl.handle.net/1902.1/17286}
\citep
{Montgomery:2012}.
The
package
for
ensemble
Bayesian
Model
Averaging,
{\tt
EBMAforecast}
is
available
through
the
Comprehensive
R-Archive
Network
at
\url
{http://cran.r-project.org/}.
\vspace
{4
mm}
\@endanenote 
\@doanenote {28}
macro:->\doublespacing
The
method
for
dealing
with
binary
outcomes
is
implicit
in
\citet
{Sloughter:2007}
and
\citet
{Sloughter:2010},
which
assume
a
discrete-continuous
distribution
for
outcomes
that
includes
a
logistic
component.
However,
they
do
not
explicitly
and
fully
develop
the
model
for
dichotomous
outcomes.
A
related
strain
of
research
on
Dynamic
Model
Averaging
\citep
[c.f.,][]{Raftery:2010,
Muhlbaier:2007}
has
recently
been
extended
for
direct
application
to
binary
outcomes
\citep
[e.g.,][]{Mccormick:2011,
Tomas:2011}.
\vspace
{4
mm}
\@endanenote 
\@doanenote {29}
macro:->\doublespacing
In
the
case
of
normally
distributed
data,
$\hat
{\sigma
}^{2(j+1)}=\frac
{1}{n}\underset
{s,t}{\sum
}\overset
{K}{\underset
{k=1}{\sum
}}\hat
{z}^{(j+1)s|t}_{k}(y-f_{k}^{s|t})^2$.
\vspace
{4
mm}
\@endanenote 
\@doanenote {30}
macro:->\doublespacing
In
the
examples
above,
we
begin
with
the
assumption
that
all
models
are
equally
likely,
$w_k
=
\frac
{1}{K}
~
\forall
~
k
\in
[1,
\ldots
,
K]$.
Critics
of
MLE
methods
and
the
EM
algorithm
have
raised
concerns
that
convergence
to
a
local
rather
than
a
global
maximum
may
occur.
We
have
found
no
differences
in
our
results
based
on
different
starting
values,
but
convergence
can
be
slow
if
starting
values
are
too
dissimilar
from
the
final
estimates.
Although
we
feel
confident
in
the
results
reported
here,
in
future
research,
we
plan
to
expand
the
model
estimation
technique
to
include
Bayesian
methods.
This
will
facilitate
comparisons
of
estimates
resulting
from
multiple
estimation
techniques.
\vspace
{4
mm}
\@endanenote 
