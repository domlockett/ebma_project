\name{Ensemble.logit}
\alias{Ensemble.logit}
%- Also NEED an '\alias' for EACH other topic documented here.
\title{
Ensemble BMA Logit Function for Binary Outcomes
}
\description{
Creates an ensemble BMA model for dichotomous outcomes.  
} 
\usage{
Ensemble.logit(y, pp.raw, exp = 3, tol = 0.01, max.iter = 1000)
}
\arguments{
  \item{y}{
The observed dichotemous outcome variable. NOTE: Only the in-sample forecasts should be included.
}
  \item{pp.raw}{
An n by k matrix of predicted probabilies, where n is the number of observations in the in-sample dataset and k is the number of component forecasts.  Each column should contain n predicted probabilities.
}
  \item{exp}{
The exponential shrinkage term.  Forecasts are raised to the (1/exp) power on the logit scale for the purposes of bias reduction.  The default value is \code{exp=3}.
}
  \item{tol}{
Tolerance for improvements in the log-likelihood before the EM algorithm will stop optimization.  The default is \code{tol= 0.01}, which is somewhat high.  Researchers may wish to reduce this by an order of magnitude for final model estimation.
}
  \item{max.iter}{
The maximum number of iterations the EM algorithm will run before stopping automatically.
}
}
\details{
Given a binary dependent variable and in-sample predictions from multiple component forecast models, \code{Ensemble.logit} fits an ensemble BMA model mixture model for dichotomous outcomes. The weights assigned to each model are derived from the individual model's performance on the in-sample outcomes (y). 
}
\value{
  \item{W}{The posterior weights assigned to each model}
  \item{log.lik}{The final log-likelihood for the EBMA model}
  \item{pred.prob}{The posterior predicted probabilities for all n in-sample observations generated by the ensemble model}
  \item{model.params}{The bias-reduction constant and predictor coeficients estimated for each of the k models}
  \item{exp}{The exponential shrinkage term specified by the user}
}
\author{
Jacob Montgomery <jacob.montgomery@duke.edu>
}
\references{
Ward, M. D., J. M. Montgomery and F. M. Hollenbach. 2011 Improving Conflict Predictions Using Ensemble Bayesian Model Averaging.  Paper presented at the 2011 meeting of the International Studies Association in Montreal, Quebec.\cr
\cr
Raftery, A. E., T. Gneiting, F. Balabdaoui and M. Polakowski. 2005 Using Bayesian Model Averaging to calibrate forecast ensembles, \emph{Monthly Weather Review} \bold{133}:1155--1174.\cr
\cr
Sloughter, J. M., A. E. Raftery, T. Gneiting and C. Fraley. 2007 Probabilistic quantitative precipitation forecasting using Bayesian model averaging, \emph{Monthly Weather Review} \bold{135}:3209--3220.\cr
\cr
Fraley, C., A. E. Raftery, T. Gneiting, 2010 Calibrating Multi-Model Forecast Ensembles with Exchangeable and Missing Members using Bayesian Model Averaging, \emph{Monthly Weather Review} \bold{138}:190--202.\cr
\cr
Sloughter, J. M., T. Gneiting and A. E. Raftery, 2010 Probabilistic wind speed forecasting using ensembles and Bayesian model averaging, \emph{Journal of the American Statistical Association}, \bold{105}:25--35.
}
\keyword{ package }
\seealso{
\code{\link{Ensemble.ICEWS}}, \code{\link{predict.Ensemble.logit}}, \code{\link{Insample}}, \code{\link{Outsample}}
}
\note{
PLEASE NOTE: This function does not currently handle missing data, but does not provide errors.
}

%% ~Make other sections like Warning with \section{Warning }{....} ~

\examples{
demo(Ensemble.ICEWS)

## The function is currently defined as
function(y, pp.raw, exp=3, tol=.01, max.iter=1000){

my.em <- function(y, PP.matrix, W, PP.W, z.numerator)
   {

   # Step 1: Calculate the Z's
     z.numerator.one <- t(apply(PP.matrix, 1, function(x){x*W}))
     z.numerator.zero <- t(apply((1-PP.matrix), 1, function(x){x*W}))
     z.numerator[y==1,] <- z.numerator.one[y==1,]
     z.numerator[y==0,] <- z.numerator.zero[y==0,]
     Z <- apply(z.numerator, 2, function(x){x/PP.W})

     # Step 2: Calculat the W's
     W <- colMeans(Z)

    # Step 3: Calculate the log-likelihood
     PP.W.one <- PP.matrix\%*\%W
     PP.W.zero <- (1-PP.matrix)\%*\%W
     PP.W[y==1] <- PP.W.one[y==1]
     PP.W[y==0] <- PP.W.zero[y==0]
     LL <-sum(log(PP.W))

     ### Output: Log-liklihood, Funny PP.W, and Model Wights
     out <- list(LL=LL, PP.W=PP.W, W=round(W, 5))
     return(out)
  }

  
  if(sum(pp.raw<0 | pp.raw>1)>0) {
    print("Error:Values greater than 1 or less than 0 included")
    stop  # Re-setting negative pred.prob to zero
    }
  num.models <- ncol(pp.raw)
  num.obs <- length(y)

  # Initiate a couple of useful matrices
  PP.matrix <- matrix(NA, nrow=num.obs, ncol=num.models)
  log.lik <- rep(NA, num.models)
  model.params <- matrix(NA, nrow=2, ncol=num.models)
  rownames(model.params) <- c("Constant", "Predictor")
  
  
  # Fit all of the basic logit model
  for(k in 1:num.models){
    pred <- pp.raw[,k]^(1/exp)
    this.model <- glm(y~pred, family="binomial")
    log.lik[k] <- this.model$deviance/(-2)
    model.params[,k] <- this.model$coefficients
    PP.matrix[,k] <- fitted(this.model)
  }

 # return(PP.matrix)
 # stop


  W <- rep(1/k, k) #Start values for vector of Probability Weights
  # Initiate a couple more useful matrices
  PP.W <- rep(NA, num.obs)
  z.numerator <- matrix(NA, nrow=num.obs, ncol=num.models)
 
  # Go through first iteration of EM
  PP.W.one <- PP.matrix\%*\%W
  PP.W.zero <- (1-PP.matrix)\%*\%W
  PP.W[y==1] <- PP.W.one[y==1]
  PP.W[y==0] <- PP.W.zero[y==0]

  this.out <- my.em(y=y, PP.matrix=PP.matrix, W=W, PP.W=PP.W, z.numerator=z.numerator)
  W <- this.out$W
  PP.W <- this.out$PP.W
  em.old <- this.out$LL

  # Now loop the EM until reach tolerance or maximum iterations
  done <- FALSE
  iter <- 1

  while(done == FALSE & iter<max.iter){
   this.out <- my.em(y=y, PP.matrix=PP.matrix, W=W, PP.W=PP.W, z.numerator=z.numerator)
   W <- this.out$W
   PP.W <- this.out$PP.W
   done <- abs(em.old-this.out$LL)<tol
   em.old <- this.out$LL
   iter <- iter+1
 }
  if (iter==max.iter){print("WARNING: Maximum iterations reached")}
  final.pp <- PP.matrix\%*\%W
  
Ensemble.output <- list(W=W, log.lik=em.old, pred.prob=final.pp, 
		   	     model.params=model.params, exp=exp)
  return(Ensemble.output)
  }
}
% Add one or more standard keywords, see file 'KEYWORDS' in the
% R documentation directory.
\keyword{BMA}

